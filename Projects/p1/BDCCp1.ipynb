{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDCC project 1 \n",
    "\n",
    "_[Big Data and Cloud Computing](http://www.dcc.fc.up.pt/~edrdo/aulas/bdcc), DCC/FCUP_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code necessary to run from the command line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # This block is required to run the program from the command line\n",
    "    # in interface with a single Spark instance\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"BDCCp1\")\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided code - auxilliary functions\n",
    "\n",
    "__You should not need to edit these.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loadMovieLensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def readCSV(file, debug=False):\n",
    "    if debug:\n",
    "      print('Reading ' + file)\n",
    "    return spark.read.csv(file, inferSchema=True, header=True)\n",
    "\n",
    "def readParquet(file, debug=False): \n",
    "    if debug:\n",
    "       print('Reading ' + file)\n",
    "    return spark.read.parquet(file)\n",
    "\n",
    "def loadMovieLensData(path, format='parquet', debug=False):\n",
    "    if format == 'parquet':\n",
    "       movies = readParquet(path +'/movies.parquet', debug)\n",
    "       ratings = readParquet(path +'/ratings.parquet', debug)\n",
    "       tags = readParquet(path +'/tags.parquet', debug)\n",
    "    else:\n",
    "       movies = readCSV(path +'/movies.csv', debug)\n",
    "       ratings = readCSV(path +'/ratings.csv', debug)\n",
    "       tags = readCSV(path +'/tags.csv', debug)\n",
    "    \n",
    "    tags = tags.withColumn('tagl', F.explode(F.split(F.lower(F.col('tag')),'[ \\*\\+\\&\\/\\%\\-\\$\\#\\'\\)\\(\\[\\[\\],.!?;:\\t\\n\"]+')))\\\n",
    "            .drop('tag')\\\n",
    "            .withColumnRenamed('tagl','tag')\n",
    "    if (debug):\n",
    "        print('> movies')\n",
    "        movies.printSchema()\n",
    "        movies.show()\n",
    "        print('> ratings')\n",
    "        ratings.printSchema()\n",
    "        ratings.show()\n",
    "        print('> tags')\n",
    "        tags.printSchema()\n",
    "        tags.show()\n",
    "    return (movies, ratings, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writeCSV / writeParquet (use them to write a data frame to CSV or Parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV(df, path): \n",
    "    df.write.csv(path, header=True, mode='overwrite')\n",
    "\n",
    "def writeParquet(df,path):\n",
    "    df.write.parquet(path, mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### createTagListDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTagListDF(csvTagList):\n",
    "    return spark.createDataFrame([ (t,) for t in csvTagList.split(' ')], ['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of functions available only in Spark 2.4 (GCP Spark instances run Spark 2.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "\n",
    "# Define F.array_intersect if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_intersect'):\n",
    "  F.array_intersect = spark.udf\\\n",
    "    .register('array_intersect', \n",
    "       lambda x,y: list(set(x) & set(y)), ArrayType(IntegerType()))\n",
    "\n",
    "# Define F.array_union if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_union'):\n",
    "  F.array_union = spark.udf\\\n",
    "    .register('array_union', \n",
    "       lambda x,y: list(set(x) | set(y)), ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to define \n",
    "\n",
    "__This is the section that will be evaluated.__\n",
    "\n",
    "__Include your code for the various functions required in the assigment below.__\n",
    "\n",
    "__You may include other auxilliary functions required for computation here\n",
    "but NOT test code (see below).__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# TODO improve debug prints\n",
    "def tfidfTags(tags, debug=False):\n",
    "    f = tags\\\n",
    "        .groupBy('tag', 'movieId')\\\n",
    "        .agg(F.count('movieId').alias('f'))\n",
    "    if debug:\n",
    "        f.show()\n",
    "    \n",
    "    f_max = f.groupBy('movieId')\\\n",
    "                .agg(F.max('f').alias('f_max'))\n",
    "    f_f_max = f.join(f_max, 'movieId')\n",
    "    if debug:\n",
    "        f_f_max.show()\n",
    "    \n",
    "    tf = f_f_max.withColumn('TF', f_f_max.f / f_f_max.f_max)\n",
    "    if debug:\n",
    "        tf.show()\n",
    "    \n",
    "    n = tags\\\n",
    "        .drop('userId')\\\n",
    "        .distinct()\\\n",
    "        .groupBy('tag')\\\n",
    "        .agg(F.count('movieId').alias('n'))\n",
    "    tf_n = tf.join(n, 'tag')\n",
    "    if debug:\n",
    "        tf_n.show()\n",
    "\n",
    "    N = tags.select('movieId').distinct().count()\n",
    "    idf = tf_n\\\n",
    "            .withColumn('IDF',  F.log2(N / tf_n.n))\n",
    "    if debug:\n",
    "        idf.show()\n",
    "    \n",
    "    tfidf = idf\\\n",
    "                .withColumn('TF_IDF',idf.TF * idf.IDF)\n",
    "    if debug:\n",
    "        tfidf.show()\n",
    "        \n",
    "    return tfidf\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTag(singleTag, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "    \n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTags(searchTags, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    searchTagsDF = createTagListDF(searchTags)\n",
    "    if debug:\n",
    "        print('> Search tags DF: ' + searchTags)\n",
    "        searchTagsDF.show()\n",
    "    # TODO\n",
    "        \n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jiMovieSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def jiMovieSimilarity(ratings, minRatings=10, debug=False):\n",
    "  # TODO\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendBySimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendBySimilarity(movieId, movies, jiForMovies, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input data set and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gs://bdcc_up201503784_311/p1/data/tiny1/movies.csv\n",
      "Reading gs://bdcc_up201503784_311/p1/data/tiny1/ratings.csv\n",
      "Reading gs://bdcc_up201503784_311/p1/data/tiny1/tags.csv\n",
      "> movies\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "+-------+--------------------+\n",
      "\n",
      "> ratings\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+-------+------+------+\n",
      "|movieId|userId|rating|\n",
      "+-------+------+------+\n",
      "|      1|     1|   4.0|\n",
      "|      3|     1|   4.0|\n",
      "|      1|     5|   4.0|\n",
      "|      2|     6|   4.0|\n",
      "|      3|     6|   5.0|\n",
      "|      4|     6|   3.0|\n",
      "|      5|     6|   5.0|\n",
      "|      1|     7|   4.5|\n",
      "|      2|     8|   4.0|\n",
      "|      4|    14|   3.0|\n",
      "|      1|    15|   2.5|\n",
      "|      1|    17|   4.5|\n",
      "|      1|    18|   3.5|\n",
      "|      2|    18|   3.0|\n",
      "|      1|    19|   4.0|\n",
      "|      2|    19|   3.0|\n",
      "|      3|    19|   3.0|\n",
      "|      2|    20|   3.0|\n",
      "|      1|    21|   3.5|\n",
      "|      2|    21|   3.5|\n",
      "+-------+------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> tags\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n",
      "+-------+------+---------+\n",
      "|movieId|userId|      tag|\n",
      "+-------+------+---------+\n",
      "|      2|    62|  fantasy|\n",
      "|      2|    62|    magic|\n",
      "|      2|    62|    board|\n",
      "|      2|    62|     game|\n",
      "|      2|    62|    robin|\n",
      "|      2|    62| williams|\n",
      "|      3|   289|    moldy|\n",
      "|      3|   289|      old|\n",
      "|      1|   336|    pixar|\n",
      "|      1|   474|    pixar|\n",
      "|      2|   474|     game|\n",
      "|      5|   474|pregnancy|\n",
      "|      5|   474|   remake|\n",
      "|      1|   567|      fun|\n",
      "+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "bucket = 'gs://bdcc_up201503784_311' # Ed's bucket \n",
    "path = '/p1/data/'\n",
    "dataset = 'tiny1'\n",
    "fullPath = bucket + path + dataset\n",
    "\n",
    "(movies, ratings, tags) = \\\n",
    "  loadMovieLensData(fullPath, format='csv', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test code \n",
    "\n",
    "__Include test code below that you may need here.__\n",
    "\n",
    "__The initial contents are only meant as an example.__\n",
    "\n",
    "__This section will NOT be evaluated.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---+-----+---+---+---+------+\n",
      "|      tag|movieId|  f|f_max| TF|  n|IDF|TF_IDF|\n",
      "+---------+-------+---+-----+---+---+---+------+\n",
      "|    pixar|      1|  2|    2|1.0|  1|2.0|   2.0|\n",
      "|      fun|      1|  1|    2|0.5|  1|2.0|   1.0|\n",
      "|     game|      2|  2|    2|1.0|  1|2.0|   2.0|\n",
      "|    robin|      2|  1|    2|0.5|  1|2.0|   1.0|\n",
      "| williams|      2|  1|    2|0.5|  1|2.0|   1.0|\n",
      "|  fantasy|      2|  1|    2|0.5|  1|2.0|   1.0|\n",
      "|    board|      2|  1|    2|0.5|  1|2.0|   1.0|\n",
      "|    magic|      2|  1|    2|0.5|  1|2.0|   1.0|\n",
      "|      old|      3|  1|    1|1.0|  1|2.0|   2.0|\n",
      "|    moldy|      3|  1|    1|1.0|  1|2.0|   2.0|\n",
      "|   remake|      5|  1|    1|1.0|  1|2.0|   2.0|\n",
      "|pregnancy|      5|  1|    1|1.0|  1|2.0|   2.0|\n",
      "+---------+-------+---+-----+---+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get TF-IDF for tags\n",
    "tfidf = tfidfTags(tags, debug=False)\n",
    "\n",
    "# tfidf.cache()\n",
    "tfidf.orderBy(['movieId','TF_IDF'],ascending=[1,0]).show()\n",
    "# tfidf.orderBy(['f','TF_IDF','movieId','tag'],ascending=[0,0,1,1]).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend by tag \n",
    "\n",
    "rm = recommendByTag('cartoon', tfidf, movies)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTag('cartoon', tfidf, movies, min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "\n",
    "rm = recommendByTag('cruise', tfidf, movies)\n",
    "rm.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "rm = recommendByTags('tom hanks cruise', tfidf, movies, numberOfResults=20)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('tom hanks airport', tfidf, movies, numberOfResults=20)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('tom hanks', tfidf, movies, numberOfResults=20)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('hitchcock birds', tfidf, movies, numberOfResults=10)\n",
    "rm.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiM = jiMovieSimilarity(ratings)\n",
    "\n",
    "#jiM.orderBy(['JI','m1','m2'], ascending=[0,1,1]).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jiM.cache()\n",
    "\n",
    "# Pulp Fiction\n",
    "#sm = recommendBySimilarity(296, movies, jiM)\n",
    "#sm.show()\n",
    "\n",
    "# Fight club\n",
    "#sm = recommendBySimilarity(2959, movies, jiM)\n",
    "#sm.show()\n",
    "    \n",
    "# Shrek\n",
    "#sm = recommendBySimilarity(4306, movies, jiM)\n",
    "#sm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}